{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea9265c-ab30-4bbb-a57a-ba4f80d043ef",
   "metadata": {},
   "source": [
    "# Visual Search System – System Overview\n",
    "\n",
    "### This notebook provides a high-level overview of the visual search backend.\n",
    "### It explains the system architecture, the flow of a search query, and the key components involved in processing image queries and generating AI explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461a8eb-a832-4542-af3b-57a9a69d3b8d",
   "metadata": {},
   "source": [
    "## System Architecture\n",
    "\n",
    "### The system consists of the following components:\n",
    "\n",
    "- **Frontend (Next.js)**: Accepts user queries and displays results.\n",
    "- **Backend (FastAPI)**:\n",
    "  - `search.py`: Encodes text queries, searches image embeddings using FAISS (or alternative vector DB).\n",
    "  - `explain.py`: Uses a captioning model to explain image relevance to the query.\n",
    "- **Embeddings**: Pre-computed image embeddings stored in FAISS or another vector store.\n",
    "- **Data**: Image files (raw and processed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c5e04-3d25-4b0a-9183-7bbfb21f56d7",
   "metadata": {},
   "source": [
    "## Query Flow\n",
    "\n",
    "1. **User inputs a natural language query**.\n",
    "2. **Backend encodes query using OpenCLIP**.\n",
    "3. **Query embedding is matched against image vectors in FAISS**.\n",
    "4. **Top-K matching images are returned**.\n",
    "5. **BLIP captioning model generates explanations per image**.\n",
    "6. **Frontend displays images + explanation text**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d73c4c-8882-4d0b-a22f-da1cadd88af6",
   "metadata": {},
   "source": [
    "## Backend Module Overview\n",
    "\n",
    "- `main.py`: FastAPI entrypoint for `/search` and `/image` routes.\n",
    "- `search.py`: Encodes queries and searches indexed image embeddings.\n",
    "- `explain.py`: Uses BLIP to generate captions + explanations.\n",
    "- `utils.py`: Handles image loading from local or URL.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from app.search import search_images\n",
    "results = search_images(\"a dog in hoodie\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b25e41-19ac-4298-b156-a90fac59984f",
   "metadata": {},
   "source": [
    "## Models Used\n",
    "\n",
    "- **OpenCLIP (`ViT-B-32`)** for text and image embeddings.\n",
    "- **BLIP** for generating captions and natural language explanations.\n",
    "\n",
    "These models are loaded once and used across queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394a2cdf-ac2f-4e66-a492-bd466602608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /image/10001.jpg\n",
      "Explanation: a dog wearing a yellow and black shirt. Relevant to query: 'a dog with hoodie'\n",
      "Image: /image/21275.jpg\n",
      "Explanation: a small dog wearing a costume on its head. Relevant to query: 'a dog with hoodie'\n",
      "Image: /image/8025.jpg\n",
      "Explanation: a dog wearing a sweater. Relevant to query: 'a dog with hoodie'\n",
      "Image: /image/15813.jpg\n",
      "Explanation: a small black dog wearing a red, white and blue striped shirt. Relevant to query: 'a dog with hoodie'\n",
      "Image: /image/6111.jpg\n",
      "Explanation: a dog sitting on a table. Relevant to query: 'a dog with hoodie'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "query = \"a dog with hoodie\"\n",
    "response = requests.get(f\"http://localhost:8000/search?query={query}\")\n",
    "results = response.json()[\"results\"]\n",
    "\n",
    "for item in results:\n",
    "    print(\"Image:\", item[\"image_url\"])\n",
    "    print(\"Explanation:\", item[\"explanation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13baef0-b2e6-443f-9bbf-d0586a0744e9",
   "metadata": {},
   "source": [
    "## File Structure Summary\n",
    "```\n",
    "visual-search-system/\n",
    "├── backend/\n",
    "│ ├── app/\n",
    "│ │ ├── main.py ← FastAPI app\n",
    "│ │ ├── search.py ← Embedding-based retrieval\n",
    "│ │ ├── explain.py ← BLIP caption generator\n",
    "│ │ ├── utils.py ← Image loading helper\n",
    "├── embeddings/\n",
    "│ ├── image.index ← FAISS index\n",
    "│ ├── metadata.npy ← Image file mappings\n",
    "├── data/\n",
    "│ ├── images/ ← Raw images\n",
    "│ ├── processed/ ← Resized, preprocessed images\n",
    "├── scripts/\n",
    "│ ├── generate_embeddings.py ← Embedding generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9094ea-b3d4-4afd-963f-ec27d58c9f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
